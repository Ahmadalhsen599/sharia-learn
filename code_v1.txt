import os
from dotenv import load_dotenv

# âœ… Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª:
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_together import Together

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env
load_dotenv()

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Together AI
llm = Together(
    model="deepseek-ai/DeepSeek-V3",
    temperature=0.3,
    max_tokens=500,
    together_api_key=os.getenv("TOGETHER_API_KEY")
)

# ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª .txt Ù…Ù† Ù…Ø¬Ù„Ø¯ data
docs = []
folder_path = "data"
for file in os.listdir(folder_path):
    if file.endswith(".txt"):
        loader = TextLoader(os.path.join(folder_path, file), encoding="utf-8")
        docs.extend(loader.load())

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹ ØµØºÙŠØ±Ø© (chunks)
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = splitter.split_documents(docs)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø¥Ù„Ù‰ Embeddings Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø¯Ø¯
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© FAISS Ù„Ù„ÙÙ‡Ø±Ø³Ø© ÙˆØ§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹
vectorstore = FAISS.from_documents(split_docs, embeddings)

# Ø¥Ù†Ø´Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© RAG Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

# Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„
question = "Ù…Ø§ Ø­ÙƒÙ… Ø§Ù„Ø¥ÙØ·Ø§Ø± Ø¹Ù…Ø¯Ù‹Ø§ ÙÙŠ Ø±Ù…Ø¶Ø§Ù†ØŸ"
answer = qa_chain.run(question)

print("\nğŸ”¹ Ø§Ù„Ø¬ÙˆØ§Ø¨:\n", answer)
